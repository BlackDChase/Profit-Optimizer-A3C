{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Agent import BOSS,GOD\n",
    "from NeuralNet import Network\n",
    "from TempEnv import TempEnv as ENV\n",
    "import log\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateSize = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Agent.GOD at 0x7f3302a93cd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "god = GOD(\n",
    "        maxEpisode=100,\n",
    "        nAgent=1,\n",
    "        debug=True,\n",
    "        trajectoryLength=25,\n",
    "        stateSize=stateSize,\n",
    "        actionSpaceDeviation=5,\n",
    "        # This means 5*2+1 number of action [-5*2.5, ... 0 , +5*2.5] percent change in price\n",
    "    )\n",
    "god"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.5000, -10.0000,  -7.5000,  -5.0000,  -2.5000,   0.0000,   2.5000,\n",
       "          5.0000,   7.5000,  10.0000,  12.5000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actionSpace = god.getActionSpace()\n",
    "actionSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TempEnv.TempEnv at 0x7f3302a3b970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = ENV(stateSize,actionSpace)\n",
    "god.giveEnvironment(env)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Agent.BOSS at 0x7f3302a3b910>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boss = god._GOD__bossAgent[0]\n",
    "boss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hypoThesis): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=20, out_features=50, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=50, out_features=11, bias=True)\n",
       "    (5): Softmax(dim=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "god._GOD__policyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hypoThesis): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU6()\n",
       "    (4): Linear(in_features=40, out_features=1, bias=True)\n",
       "    (5): ReLU6()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "god._GOD__criticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss.startState = boss.god.reset()\n",
    "boss.gatherAndStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss.vPredicted = Tensor(len(boss.vPredicted))\n",
    "for i in range(boss.trajectoryLength):\n",
    "    state=boss.trajectoryS[i]\n",
    "    boss.vPredicted[i]=boss.god._getCriticValue(state)\n",
    "\n",
    "boss.vTarget = Tensor(len(boss.vTarget))\n",
    "boss.vTarget[boss.trajectoryLength-1] = boss.trajectoryR[boss.trajectoryLength-1]\n",
    "for i in reversed(range(boss.trajectoryLength-1)):\n",
    "    boss.vTarget[i] = boss.trajectoryR[i].clone() + boss.ɤ*boss.vTarget[i+1].clone()\n",
    "\n",
    "vPredLast = boss.vPredicted[boss.trajectoryLength-1]\n",
    "boss.advantage =  Tensor(len(boss.advantage))\n",
    "boss.advantage[-1]=vPredLast\n",
    "for i in reversed(range(boss.trajectoryLength-1)):\n",
    "    boss.advantage[i] = boss.trajectoryR[i].clone() + boss.ɤ*boss.advantage[i+1].clone() - boss.vPredicted[i].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(270.0083, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actionProb = boss.trajectoryA\n",
    "advantage = boss.advantage.detach()\n",
    "loss = -1*torch.sum(advantage*torch.log(actionProb))\n",
    "loss/=boss.trajectoryLength\n",
    "boss.god._updatePolicy(loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "boss.startState = boss.god.reset()\n",
    "boss.gatherAndStore()\n",
    "boss.vPredicted = Tensor(len(boss.vPredicted))\n",
    "for i in range(boss.trajectoryLength):\n",
    "    state=boss.trajectoryS[i]\n",
    "    boss.vPredicted[i]=boss.god._getCriticValue(state)\n",
    "\n",
    "boss.vTarget = Tensor(len(boss.vTarget))\n",
    "boss.vTarget[boss.trajectoryLength-1] = boss.trajectoryR[boss.trajectoryLength-1]\n",
    "for i in reversed(range(boss.trajectoryLength-1)):\n",
    "    boss.vTarget[i] = boss.trajectoryR[i].clone() + boss.ɤ*boss.vTarget[i+1].clone()\n",
    "\n",
    "vPredLast = boss.vPredicted[boss.trajectoryLength-1]\n",
    "boss.advantage =  Tensor(len(boss.advantage))\n",
    "boss.advantage[-1]=vPredLast\n",
    "for i in reversed(range(boss.trajectoryLength-1)):\n",
    "    boss.advantage[i] = boss.trajectoryR[i].clone() + boss.ɤ*boss.advantage[i+1].clone() - boss.vPredicted[i].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/black/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: Error detected in MmBackward. Traceback of forward call that caused the error:\n",
      "  File \"/home/black/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/black/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/black/lib/python3.8/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/black/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/black/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/black/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 714, in __init__\n",
      "    self.run()\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/home/black/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/black/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/black/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2866, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/black/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/black/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/black/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3071, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/black/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/black/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-7f34fddf91ef>\", line 2, in <module>\n",
      "    boss.gatherAndStore()\n",
      "  File \"/media/black/Data/GIT/OptimizeDemandResponse/Profit-Optimizer-A3C/modules/Agent.py\", line 337, in gatherAndStore\n",
      "    action,actionProb = self.getAction(currentState)\n",
      "  File \"/media/black/Data/GIT/OptimizeDemandResponse/Profit-Optimizer-A3C/modules/Agent.py\", line 358, in getAction\n",
      "    actionProb = self.god._getAction(state)\n",
      "  File \"/media/black/Data/GIT/OptimizeDemandResponse/Profit-Optimizer-A3C/modules/Agent.py\", line 184, in _getAction\n",
      "    actionProbab = self.__policyNet.forward(state)\n",
      "  File \"/media/black/Data/GIT/OptimizeDemandResponse/Profit-Optimizer-A3C/modules/NeuralNet.py\", line 98, in forward\n",
      "    output = self.hypoThesis(currentState)\n",
      "  File \"/home/black/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/black/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/black/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/black/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 93, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/black/.local/lib/python3.8/site-packages/torch/nn/functional.py\", line 1692, in linear\n",
      "    output = input.matmul(weight.t())\n",
      " (Triggered internally at  /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [50, 11]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1ba0fa85cf74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvantage\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactionProb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m/=\u001b[0m\u001b[0mboss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectoryLength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mboss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updatePolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/black/Data/GIT/OptimizeDemandResponse/Profit-Optimizer-A3C/modules/Agent.py\u001b[0m in \u001b[0;36m_updatePolicy\u001b[0;34m(self, lossP)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updatePolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlossP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__policyNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mlossP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__policyNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [50, 11]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "actionProb = boss.trajectoryA\n",
    "advantage = boss.advantage.detach()\n",
    "\"\"\"\n",
    "Advantage is calculated using critc\n",
    "So issue is most probably with actionProb\n",
    "what else could we do to get these things right\n",
    "- May be its because how we are making it, actionProb[actionIndex]\n",
    "- We should rather copy that index\n",
    "- find another way to run backprop for it\n",
    "\"\"\" \n",
    "loss = -1*torch.sum(advantage*torch.log(actionProb))\n",
    "loss/=boss.trajectoryLength\n",
    "boss.god._updatePolicy(loss)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
